{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeOeMSHCgUliawca0W5UHt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kizons/DS/blob/main/Customer_churn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "Tj49ULacLGE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 1: Load and prepare data ----\n",
        "# Replace `your_dataframe` with your actual dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "categorical_cols = ['state', 'area_code', 'international_plan', 'voice_mail_plan']\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols), index=df.index)\n",
        "\n",
        "# Merge and drop\n",
        "df = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)\n"
      ],
      "metadata": {
        "id": "uscUnZ23LIAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 2: Split into train, validation, test (60/20/20) ----\n",
        "temp_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
        "train_df, valid_df = train_test_split(temp_df, test_size=0.25, random_state=42, shuffle=True) # 0.25 of 0.8 = 0.2\n"
      ],
      "metadata": {
        "id": "DIAN7cM3LT5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 3: Scale and oversample (only on training data) ----\n",
        "def preprocess(dataframe, oversample=False):\n",
        "  X = dataframe.drop(columns='churn').values\n",
        "  y = dataframe['churn'].values\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "\n",
        "  if oversample:\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X, y = sm.fit_resample(X, y)\n",
        "\n",
        "  return X, y\n",
        "\n"
      ],
      "metadata": {
        "id": "oyMYapWoLcsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = preprocess(train_df, oversample=True)\n",
        "X_valid, y_valid = preprocess(valid_df, oversample=False)\n",
        "X_test, y_test = preprocess(test_df, oversample=False)\n"
      ],
      "metadata": {
        "id": "AkDOYTQbMtbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 4: Train and evaluate models ----\n",
        "\n",
        "# KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=19)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(\"KNN Results:\\n\", classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "4ewl-unvLro6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53b68fb-8db6-4ff4-e238-bbb1b8e1f45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Results:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          no       0.89      0.68      0.77       721\n",
            "         yes       0.23      0.53      0.32       129\n",
            "\n",
            "    accuracy                           0.66       850\n",
            "   macro avg       0.56      0.61      0.55       850\n",
            "weighted avg       0.79      0.66      0.70       850\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "print(\"Naive Bayes Results:\\n\", classification_report(y_test, y_pred_nb))"
      ],
      "metadata": {
        "id": "QHDSSIymNSnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab081bc7-87ba-4811-f16b-3c044c6bbe2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          no       0.88      0.46      0.60       721\n",
            "         yes       0.17      0.64      0.27       129\n",
            "\n",
            "    accuracy                           0.49       850\n",
            "   macro avg       0.53      0.55      0.44       850\n",
            "weighted avg       0.77      0.49      0.55       850\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_log = logreg.predict(X_test)\n",
        "print(\"Logistic Regression Results:\\n\", classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "id": "vtp5eyzINVg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c88f94-de2e-4b24-ec9a-dd299c196aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          no       0.93      0.80      0.86       721\n",
            "         yes       0.38      0.68      0.49       129\n",
            "\n",
            "    accuracy                           0.78       850\n",
            "   macro avg       0.66      0.74      0.68       850\n",
            "weighted avg       0.85      0.78      0.81       850\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of the 3 models, Logistic Regression Model gave the best result"
      ],
      "metadata": {
        "id": "Xh8Q0xOW5CAm"
      }
    }
  ]
}